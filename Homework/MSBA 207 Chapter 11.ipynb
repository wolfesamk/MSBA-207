{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcXBU2Tc8u8n"
   },
   "source": [
    "# Chapter 11 Assignment: Neural nets (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Chapter 11 of DMBA and review relevant resources in Module - Chapter 11 Neural Nets before starting this assignment. Provide your answers to all problems below, save this Jupyter notebook (.ipynb file), and then submit it along with your Excel worksheet in Canvas by the due date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages for this chapter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "import scikitplot as skplt\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from dmba import classificationSummary, regressionSummary, liftChart\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "UAFvO1Z78u8o"
   },
   "outputs": [],
   "source": [
    "# Working directory:\n",
    "# If you keep your data in a different folder, replace the argument of the `Path`\n",
    "# DATA = Path('/Users/user/data/dmba/')\n",
    "DATA = Path('E:/Aliit/School/MSBA/206/MSBA-206/dmba/')\n",
    "# and then load data using \n",
    "# pd.read_csv(DATA / ‘filename.csv’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uY9BllHr8u8o"
   },
   "source": [
    "# 1: Credit Card Use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5x7hL_Z8u8o"
   },
   "source": [
    "Consider the hypothetical bank data in Table 11.7 of the DMBA textbook on consumers’ use of credit card credit facilities. Create a small worksheet in Excel to illustrate one pass through a simple neural network (Randomly generate initial weight values)\n",
    "\n",
    "_Years: number of years the customer has been with the bank_\n",
    "\n",
    "_Salary: customer’s salary (in thousands of dollars)_\n",
    "\n",
    "_Used Credit:<br> \n",
    "1 = customer has left an unpaid credit card balance at the end of at least one month in the prior year, <br>\n",
    "0 = balance was paid off at the end of each month_\n",
    "<p>\n",
    "Upload your Excel worksheet via canvas submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please see included file 'MSBA 207 Chapter 11 Question 1.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMIhT1GJ8u8r"
   },
   "source": [
    "# 2: Neural Net Evolution. \n",
    "\n",
    "A neural net typically starts out with random coeffcients; hence, it produces essentially random predictions when presented with its first case. What is the key ingredient by which the net evolves to produce a more accurate prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the neural nets are currently established to be forwards only, they evolve by taking the the error of the first random weights and adding it to the previous weights guess to iteratively update the weights data point by data point until the desired result is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXmEJsk98u8u"
   },
   "source": [
    "# 3: Direct Mailing to Airline Customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOpB6_z18u8u"
   },
   "source": [
    "East-West Airlines has entered into a partnership with the wireless phone company Telcon to sell the latter’s service via direct mail. The file _EastWestAirlinesNN.csv_ contains a subset of a data sample of who has already received a test oﬀer. About 13% accepted.\n",
    "\n",
    "You are asked to develop a model to classify East–West customers as to whether they purchase a wireless phone service contract (outcome variable Phone_Sale). This model will be used to classify additional customers.\n",
    "\n",
    "Review the <a href=\"https://www.thecasesolutions.com/project-data-mining-on-east-west-airlines-65598\">Data Dictionary</a> first to understand the data.\n",
    "\n",
    "You will need <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html?highlight=mlpclassifier#sklearn.neural_network.MLPClassifier\">sklearn.neural_network.MLPClassifier</a> so review this documentation first. Try both ‘logistic’ and ‘relu’ activation functions for the hidden layer.<p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "sXc4-9lw8u8u",
    "outputId": "f8d215b2-ad75-42d7-ca61-8417d7c1bbc1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "airline_df = pd.read_csv(DATA / 'EastWestAirlinesNN.csv').drop(columns='ID#').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a.__ Run a neural net model on these data, using a single hidden layer with five nodes. Try both ‘logistic’ and ‘relu’ activation functions for the hidden layer. Remember to first convert categorical variables into dummies and scale numerical predictor variables to a 0–1 (use the scikit-learn transformer <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">MinMaxScaler() </a> (also see Chapter 2.4 of DMBA).<p>\n",
    "Use the training data to learn the transformation (see Table 7.2 in DMBA) rescaling the entire data (numerical variables only) to [0, 1] via \"clip=True\" in: <p>\n",
    "scaleInput = MinMaxScaler(feature_range=(0, 1), clip=True)<p>\n",
    "clip=True to clip transformed values of held-out data to provided feature range<p>\n",
    "Do not scale binary dummy variables. Create a decile-wise lift chart for the training and validation sets. Interpret the meaning (in business terms) of the leftmost bar of the validation decile-wise lift chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topflight</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Qual_miles</th>\n",
       "      <th>cc1_miles?</th>\n",
       "      <th>cc2_miles?</th>\n",
       "      <th>cc3_miles?</th>\n",
       "      <th>Bonus_miles</th>\n",
       "      <th>Bonus_trans</th>\n",
       "      <th>Flight_miles_12mo</th>\n",
       "      <th>Flight_trans_12</th>\n",
       "      <th>Online_12</th>\n",
       "      <th>Email</th>\n",
       "      <th>Club_member</th>\n",
       "      <th>Any_cc_miles_12mo</th>\n",
       "      <th>Phone_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>41354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4123.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>97752.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43300.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3620.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4832.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4985 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topflight  Balance  Qual_miles  cc1_miles?  cc2_miles?  cc3_miles?  \\\n",
       "0           0.0  28143.0         0.0         0.0         1.0         0.0   \n",
       "1           0.0  19244.0         0.0         0.0         0.0         0.0   \n",
       "2           0.0  41354.0         0.0         1.0         0.0         0.0   \n",
       "3           0.0  14776.0         0.0         0.0         0.0         0.0   \n",
       "4           1.0  97752.0         0.0         1.0         0.0         0.0   \n",
       "...         ...      ...         ...         ...         ...         ...   \n",
       "4980        0.0    227.0         0.0         1.0         0.0         0.0   \n",
       "4981        0.0   3620.0      1435.0         0.0         0.0         0.0   \n",
       "4982        0.0  10013.0      2436.0         0.0         0.0         0.0   \n",
       "4983        0.0   4832.0         0.0         0.0         0.0         0.0   \n",
       "4984        0.0    500.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "      Bonus_miles  Bonus_trans  Flight_miles_12mo  Flight_trans_12  Online_12  \\\n",
       "0           174.0          1.0                0.0              0.0        0.0   \n",
       "1           215.0          2.0                0.0              0.0        0.0   \n",
       "2          4123.0          4.0                0.0              0.0        0.0   \n",
       "3           500.0          1.0                0.0              0.0        0.0   \n",
       "4         43300.0         26.0             2077.0              4.0        0.0   \n",
       "...           ...          ...                ...              ...        ...   \n",
       "4980        227.0          1.0                0.0              0.0        0.0   \n",
       "4981          0.0          0.0                0.0              0.0        0.0   \n",
       "4982          0.0          0.0                0.0              0.0        0.0   \n",
       "4983          0.0          0.0                0.0              0.0        0.0   \n",
       "4984          0.0          0.0                0.0              0.0        0.0   \n",
       "\n",
       "      Email  Club_member  Any_cc_miles_12mo  Phone_sale  \n",
       "0       1.0          0.0                1.0         0.0  \n",
       "1       0.0          0.0                0.0         0.0  \n",
       "2       1.0          0.0                1.0         0.0  \n",
       "3       1.0          0.0                0.0         0.0  \n",
       "4       1.0          0.0                1.0         0.0  \n",
       "...     ...          ...                ...         ...  \n",
       "4980    0.0          0.0                1.0         0.0  \n",
       "4981    1.0          0.0                0.0         0.0  \n",
       "4982    1.0          0.0                0.0         0.0  \n",
       "4983    1.0          0.0                0.0         0.0  \n",
       "4984    0.0          0.0                0.0         0.0  \n",
       "\n",
       "[4985 rows x 15 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome = 'Phone_sale'\n",
    "airline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topflight            float64\n",
       "Balance              float64\n",
       "Qual_miles           float64\n",
       "cc1_miles?           float64\n",
       "cc2_miles?           float64\n",
       "cc3_miles?           float64\n",
       "Bonus_miles          float64\n",
       "Bonus_trans          float64\n",
       "Flight_miles_12mo    float64\n",
       "Flight_trans_12      float64\n",
       "Online_12            float64\n",
       "Email                float64\n",
       "Club_member          float64\n",
       "Any_cc_miles_12mo    float64\n",
       "Phone_sale           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topflight              uint8\n",
      "Balance              float64\n",
      "Qual_miles           float64\n",
      "cc1_miles?             uint8\n",
      "cc2_miles?             uint8\n",
      "cc3_miles?             uint8\n",
      "Bonus_miles          float64\n",
      "Bonus_trans          float64\n",
      "Flight_miles_12mo    float64\n",
      "Flight_trans_12      float64\n",
      "Online_12            float64\n",
      "Email                  uint8\n",
      "Club_member            uint8\n",
      "Any_cc_miles_12mo      uint8\n",
      "Phone_sale             uint8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "airline_df['Topflight'] = airline_df['Topflight'].astype('uint8')\n",
    "airline_df['cc1_miles?'] = airline_df['cc1_miles?'].astype('uint8')\n",
    "airline_df['cc2_miles?'] = airline_df['cc2_miles?'].astype('uint8')\n",
    "airline_df['cc3_miles?'] = airline_df['cc3_miles?'].astype('uint8')\n",
    "airline_df['Email'] = airline_df['Email'].astype('uint8')\n",
    "airline_df['Club_member'] = airline_df['Club_member'].astype('uint8')\n",
    "airline_df['Any_cc_miles_12mo'] = airline_df['Any_cc_miles_12mo'].astype('uint8')\n",
    "airline_df['Phone_sale'] = airline_df['Phone_sale'].astype('uint8')\n",
    "print(airline_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topflight</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Qual_miles</th>\n",
       "      <th>cc1_miles?</th>\n",
       "      <th>cc2_miles?</th>\n",
       "      <th>cc3_miles?</th>\n",
       "      <th>Bonus_miles</th>\n",
       "      <th>Bonus_trans</th>\n",
       "      <th>Flight_miles_12mo</th>\n",
       "      <th>Flight_trans_12</th>\n",
       "      <th>Online_12</th>\n",
       "      <th>Email</th>\n",
       "      <th>Club_member</th>\n",
       "      <th>Any_cc_miles_12mo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3677</th>\n",
       "      <td>0</td>\n",
       "      <td>7847.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>0</td>\n",
       "      <td>18179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5488.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>0</td>\n",
       "      <td>46654.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1</td>\n",
       "      <td>1302051.0</td>\n",
       "      <td>2706.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90653.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>0</td>\n",
       "      <td>18656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4752.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>0</td>\n",
       "      <td>44101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57114.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>0</td>\n",
       "      <td>50658.0</td>\n",
       "      <td>1674.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>1</td>\n",
       "      <td>289351.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147787.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>0</td>\n",
       "      <td>28867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19169.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>182317.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19489.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topflight    Balance  Qual_miles  cc1_miles?  cc2_miles?  cc3_miles?  \\\n",
       "3677          0     7847.0         0.0           0           0           0   \n",
       "3340          0    18179.0         0.0           1           0           0   \n",
       "2563          0    46654.0         0.0           1           0           0   \n",
       "220           1  1302051.0      2706.0           1           0           0   \n",
       "3390          0    18656.0         0.0           0           1           0   \n",
       "...         ...        ...         ...         ...         ...         ...   \n",
       "2895          0    44101.0         0.0           1           0           0   \n",
       "2763          0    50658.0      1674.0           0           0           0   \n",
       "905           1   289351.0         0.0           1           0           0   \n",
       "3980          0    28867.0         0.0           1           0           0   \n",
       "235           1   182317.0         0.0           1           0           0   \n",
       "\n",
       "      Bonus_miles  Bonus_trans  Flight_miles_12mo  Flight_trans_12  Online_12  \\\n",
       "3677          0.0          0.0                0.0              0.0        0.0   \n",
       "3340       5488.0          3.0                0.0              0.0        0.0   \n",
       "2563       3215.0          6.0                0.0              0.0        0.0   \n",
       "220       90653.0         32.0             3050.0              7.0        0.0   \n",
       "3390       4752.0         11.0                0.0              0.0        0.0   \n",
       "...           ...          ...                ...              ...        ...   \n",
       "2895      57114.0         19.0                0.0              0.0        0.0   \n",
       "2763       1600.0          3.0              500.0              1.0        0.0   \n",
       "905      147787.0         35.0              500.0              1.0        0.0   \n",
       "3980      19169.0         28.0                0.0              0.0        0.0   \n",
       "235       19489.0         17.0              273.0              1.0        0.0   \n",
       "\n",
       "      Email  Club_member  Any_cc_miles_12mo  \n",
       "3677      0            0                  0  \n",
       "3340      1            0                  1  \n",
       "2563      1            0                  1  \n",
       "220       1            1                  1  \n",
       "3390      1            0                  1  \n",
       "...     ...          ...                ...  \n",
       "2895      1            0                  1  \n",
       "2763      0            0                  0  \n",
       "905       1            1                  1  \n",
       "3980      1            0                  1  \n",
       "235       1            0                  1  \n",
       "\n",
       "[2991 rows x 14 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = airline_df.drop(columns=outcome)\n",
    "y = airline_df[outcome]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topflight</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Qual_miles</th>\n",
       "      <th>cc1_miles?</th>\n",
       "      <th>cc2_miles?</th>\n",
       "      <th>cc3_miles?</th>\n",
       "      <th>Bonus_miles</th>\n",
       "      <th>Bonus_trans</th>\n",
       "      <th>Flight_miles_12mo</th>\n",
       "      <th>Flight_trans_12</th>\n",
       "      <th>Online_12</th>\n",
       "      <th>Email</th>\n",
       "      <th>Club_member</th>\n",
       "      <th>Any_cc_miles_12mo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023796</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.267974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393069</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.098971</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247644</td>\n",
       "      <td>0.215909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>0.165775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640800</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083116</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084504</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topflight   Balance  Qual_miles  cc1_miles?  cc2_miles?  cc3_miles?  \\\n",
       "0           0.0  0.006024    0.000000         0.0         0.0         0.0   \n",
       "1           0.0  0.013959    0.000000         1.0         0.0         0.0   \n",
       "2           0.0  0.035828    0.000000         1.0         0.0         0.0   \n",
       "3           1.0  1.000000    0.267974         1.0         0.0         0.0   \n",
       "4           0.0  0.014325    0.000000         0.0         1.0         0.0   \n",
       "...         ...       ...         ...         ...         ...         ...   \n",
       "2986        0.0  0.033867    0.000000         1.0         0.0         0.0   \n",
       "2987        0.0  0.038903    0.165775         0.0         0.0         0.0   \n",
       "2988        1.0  0.222225    0.000000         1.0         0.0         0.0   \n",
       "2989        0.0  0.022167    0.000000         1.0         0.0         0.0   \n",
       "2990        1.0  0.140020    0.000000         1.0         0.0         0.0   \n",
       "\n",
       "      Bonus_miles  Bonus_trans  Flight_miles_12mo  Flight_trans_12  Online_12  \\\n",
       "0        0.000000     0.000000           0.000000         0.000000        0.0   \n",
       "1        0.023796     0.034091           0.000000         0.000000        0.0   \n",
       "2        0.013940     0.068182           0.000000         0.000000        0.0   \n",
       "3        0.393069     0.363636           0.098971         0.132075        0.0   \n",
       "4        0.020605     0.125000           0.000000         0.000000        0.0   \n",
       "...           ...          ...                ...              ...        ...   \n",
       "2986     0.247644     0.215909           0.000000         0.000000        0.0   \n",
       "2987     0.006938     0.034091           0.016225         0.018868        0.0   \n",
       "2988     0.640800     0.397727           0.016225         0.018868        0.0   \n",
       "2989     0.083116     0.318182           0.000000         0.000000        0.0   \n",
       "2990     0.084504     0.193182           0.008859         0.018868        0.0   \n",
       "\n",
       "      Email  Club_member  Any_cc_miles_12mo  \n",
       "0       0.0          0.0                0.0  \n",
       "1       1.0          0.0                1.0  \n",
       "2       1.0          0.0                1.0  \n",
       "3       1.0          1.0                1.0  \n",
       "4       1.0          0.0                1.0  \n",
       "...     ...          ...                ...  \n",
       "2986    1.0          0.0                1.0  \n",
       "2987    0.0          0.0                0.0  \n",
       "2988    1.0          1.0                1.0  \n",
       "2989    1.0          0.0                1.0  \n",
       "2990    1.0          0.0                1.0  \n",
       "\n",
       "[2991 rows x 14 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaleInput = MinMaxScaler(feature_range=(0,1),clip=True)\n",
    "train_X = pd.DataFrame(scaleInput.fit_transform(train_X),columns=train_X.columns)\n",
    "valid_X = pd.DataFrame(scaleInput.fit_transform(valid_X),columns=valid_X.columns)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(5,), max_iter=10000, random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(5,), max_iter=10000, random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(5,), max_iter=10000, random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train neural network with 1 layer and 5 hidden nodes and logistic\n",
    "MLPC_Logi = MLPClassifier(hidden_layer_sizes=(5,), activation='logistic', solver='lbfgs', random_state=1, max_iter=10000)\n",
    "MLPC_Logi.fit(train_X, train_y.values)\n",
    "\n",
    "# train neural network with 1 layer and 5 hidden nodes and relu\n",
    "MLPC_Relu = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', solver='lbfgs', random_state=1, max_iter=10000)\n",
    "MLPC_Relu.fit(train_X, train_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.8776)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 2609    4\n",
      "     1  362   16\n"
     ]
    }
   ],
   "source": [
    "classificationSummary(train_y, MLPC_Logi.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.8576)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1698   19\n",
      "     1  265   12\n"
     ]
    }
   ],
   "source": [
    "classificationSummary(valid_y, MLPC_Logi.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPC_Logi_probas = MLPC_Logi.predict_proba(valid_X)\n",
    "MLPC_Logi_probas_df = pd.DataFrame(MLPC_Logi_probas)\n",
    "MLPC_Logi_probas_df['Predicted'] = MLPC_Logi_probas_df[1]\n",
    "MLPC_Logi_probas_df = MLPC_Logi_probas_df.drop(columns=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MLPC_Logi_Results = pd.DataFrame({'Predicted': MLPC_Logi_probas_df['Predicted'], 'Actual': valid_y})\n",
    "liftChart(MLPC_Logi_Results.sort_values(by=['Predicted'], ascending=False).Predicted, labelBars=True, title='Decile Lift Chart')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.8756)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 2608    5\n",
      "     1  367   11\n"
     ]
    }
   ],
   "source": [
    "classificationSummary(train_y, MLPC_Relu.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.8581)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1705   12\n",
      "     1  271    6\n"
     ]
    }
   ],
   "source": [
    "classificationSummary(valid_y, MLPC_Relu.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPC_Relu_probas = MLPC_Relu.predict_proba(valid_X)\n",
    "MLPC_Relu_probas_df = pd.DataFrame(MLPC_Relu_probas)\n",
    "MLPC_Relu_probas_df['Predicted'] = MLPC_Relu_probas_df[1]\n",
    "MLPC_Relu_probas_df = MLPC_Relu_probas_df.drop(columns=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MLPC_Relu_Results = pd.DataFrame({'Predicted': MLPC_Relu_probas_df['Predicted'], 'Actual': valid_y})\n",
    "liftChart(MLPC_Relu_Results.sort_values(by=['Predicted'], ascending=False).Predicted, labelBars=True, title='Decile Lift Chart')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJEhJ_uM8u8v"
   },
   "source": [
    "__b.__ Comment on the diﬀerence between the training and validation lift charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the Decile Lift Charts, we see that taking the top 10% of the models ranked by either model we get around 2.0-2.2 times as many 1's as we would with a random selection. The Relu model performs better overall in creating a heavier front load of positive results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilztl-lY8u8v"
   },
   "source": [
    "__c.__ Run a second neural net model on the data, this time setting the number of hidden nodes to 1. Comment now on the diﬀerence between this model and the model you ran earlier, and how overftting might have aﬀected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(1,), max_iter=10000, random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(1,), max_iter=10000, random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(1,), max_iter=10000, random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train neural network with 1 layer and 5 hidden nodes and relu\n",
    "MLPC_Relu = MLPClassifier(hidden_layer_sizes=(1,), activation='relu', solver='lbfgs', random_state=1, max_iter=10000)\n",
    "MLPC_Relu.fit(train_X, train_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.8736)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 2613    0\n",
      "     1  378    0\n"
     ]
    }
   ],
   "source": [
    "classificationSummary(train_y, MLPC_Relu.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.8611)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1717    0\n",
      "     1  277    0\n"
     ]
    }
   ],
   "source": [
    "classificationSummary(valid_y, MLPC_Relu.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPC_Relu_probas = MLPC_Relu.predict_proba(valid_X)\n",
    "MLPC_Relu_probas_df = pd.DataFrame(MLPC_Relu_probas)\n",
    "MLPC_Relu_probas_df['Predicted'] = MLPC_Relu_probas_df[1]\n",
    "MLPC_Relu_probas_df = MLPC_Relu_probas_df.drop(columns=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MLPC_Relu_Results = pd.DataFrame({'Predicted': MLPC_Relu_probas_df['Predicted'], 'Actual': valid_y})\n",
    "liftChart(MLPC_Relu_Results.sort_values(by=['Predicted'], ascending=False).Predicted, labelBars=True, title='Decile Lift Chart')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We appear to be under fitting in the negative, resulting in no results of the phone sale outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FiYqZTV8u8v"
   },
   "source": [
    "__d.__ What sort of information, if any, is provided about the eﬀects of the various variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because of the black box nature of neural nets, we have a hard time understanding the effects of the various variables. We could manually adjust one variable at a time with random state =1 and catalogue the changes in the models performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFblDWPh8u8w"
   },
   "source": [
    "__e.__ Use GridSearchCV() to search for the number of nodes with the best score in a single layer of hidden nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.873621029474989\n",
      "Best parameters:  {'hidden_layer_sizes': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002781</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>1</td>\n",
       "      <td>{'hidden_layer_sizes': 1}</td>\n",
       "      <td>0.873122</td>\n",
       "      <td>0.874582</td>\n",
       "      <td>0.874582</td>\n",
       "      <td>0.872910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873621</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.873746</td>\n",
       "      <td>0.873381</td>\n",
       "      <td>0.873381</td>\n",
       "      <td>0.873799</td>\n",
       "      <td>0.873799</td>\n",
       "      <td>0.873621</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219649</td>\n",
       "      <td>0.147265</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>2</td>\n",
       "      <td>{'hidden_layer_sizes': 2}</td>\n",
       "      <td>0.873122</td>\n",
       "      <td>0.874582</td>\n",
       "      <td>0.874582</td>\n",
       "      <td>0.872910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873287</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>2</td>\n",
       "      <td>0.873746</td>\n",
       "      <td>0.873381</td>\n",
       "      <td>0.874216</td>\n",
       "      <td>0.874634</td>\n",
       "      <td>0.875888</td>\n",
       "      <td>0.874373</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.119757</td>\n",
       "      <td>0.045211</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>3</td>\n",
       "      <td>{'hidden_layer_sizes': 3}</td>\n",
       "      <td>0.873122</td>\n",
       "      <td>0.872910</td>\n",
       "      <td>0.872910</td>\n",
       "      <td>0.872910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872952</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873799</td>\n",
       "      <td>0.875888</td>\n",
       "      <td>0.876306</td>\n",
       "      <td>0.873799</td>\n",
       "      <td>0.874958</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.229769</td>\n",
       "      <td>0.090151</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>4</td>\n",
       "      <td>{'hidden_layer_sizes': 4}</td>\n",
       "      <td>0.873122</td>\n",
       "      <td>0.871237</td>\n",
       "      <td>0.874582</td>\n",
       "      <td>0.872910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871949</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>4</td>\n",
       "      <td>0.873746</td>\n",
       "      <td>0.878395</td>\n",
       "      <td>0.873381</td>\n",
       "      <td>0.874634</td>\n",
       "      <td>0.874634</td>\n",
       "      <td>0.874958</td>\n",
       "      <td>0.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429395</td>\n",
       "      <td>0.127031</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>5</td>\n",
       "      <td>{'hidden_layer_sizes': 5}</td>\n",
       "      <td>0.874791</td>\n",
       "      <td>0.864548</td>\n",
       "      <td>0.871237</td>\n",
       "      <td>0.866221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869942</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>9</td>\n",
       "      <td>0.875836</td>\n",
       "      <td>0.879649</td>\n",
       "      <td>0.877142</td>\n",
       "      <td>0.875052</td>\n",
       "      <td>0.875470</td>\n",
       "      <td>0.876630</td>\n",
       "      <td>0.001664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.637211</td>\n",
       "      <td>0.256696</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>6</td>\n",
       "      <td>{'hidden_layer_sizes': 6}</td>\n",
       "      <td>0.874791</td>\n",
       "      <td>0.867893</td>\n",
       "      <td>0.871237</td>\n",
       "      <td>0.866221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870276</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>6</td>\n",
       "      <td>0.876672</td>\n",
       "      <td>0.876306</td>\n",
       "      <td>0.877977</td>\n",
       "      <td>0.876724</td>\n",
       "      <td>0.877560</td>\n",
       "      <td>0.877048</td>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.644090</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>7</td>\n",
       "      <td>{'hidden_layer_sizes': 7}</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.867893</td>\n",
       "      <td>0.862876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866598</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>11</td>\n",
       "      <td>0.875836</td>\n",
       "      <td>0.876724</td>\n",
       "      <td>0.877977</td>\n",
       "      <td>0.878395</td>\n",
       "      <td>0.879649</td>\n",
       "      <td>0.877716</td>\n",
       "      <td>0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.808015</td>\n",
       "      <td>0.182203</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>8</td>\n",
       "      <td>{'hidden_layer_sizes': 8}</td>\n",
       "      <td>0.876461</td>\n",
       "      <td>0.871237</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871613</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>5</td>\n",
       "      <td>0.877926</td>\n",
       "      <td>0.874634</td>\n",
       "      <td>0.878813</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.877977</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.788429</td>\n",
       "      <td>0.235601</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>9</td>\n",
       "      <td>{'hidden_layer_sizes': 9}</td>\n",
       "      <td>0.873122</td>\n",
       "      <td>0.867893</td>\n",
       "      <td>0.871237</td>\n",
       "      <td>0.866221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869942</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>8</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.878395</td>\n",
       "      <td>0.877142</td>\n",
       "      <td>0.877142</td>\n",
       "      <td>0.879649</td>\n",
       "      <td>0.877549</td>\n",
       "      <td>0.001414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.820932</td>\n",
       "      <td>0.110276</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>10</td>\n",
       "      <td>{'hidden_layer_sizes': 10}</td>\n",
       "      <td>0.874791</td>\n",
       "      <td>0.866221</td>\n",
       "      <td>0.872910</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870276</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>7</td>\n",
       "      <td>0.877090</td>\n",
       "      <td>0.877977</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.877977</td>\n",
       "      <td>0.879649</td>\n",
       "      <td>0.878385</td>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.929621</td>\n",
       "      <td>0.201192</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>11</td>\n",
       "      <td>{'hidden_layer_sizes': 11}</td>\n",
       "      <td>0.869783</td>\n",
       "      <td>0.874582</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>0.862876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867268</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>10</td>\n",
       "      <td>0.876254</td>\n",
       "      <td>0.881738</td>\n",
       "      <td>0.879649</td>\n",
       "      <td>0.878395</td>\n",
       "      <td>0.877142</td>\n",
       "      <td>0.878636</td>\n",
       "      <td>0.001930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.941068</td>\n",
       "      <td>0.198130</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>12</td>\n",
       "      <td>{'hidden_layer_sizes': 12}</td>\n",
       "      <td>0.868114</td>\n",
       "      <td>0.864548</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>0.861204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863589</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>16</td>\n",
       "      <td>0.883361</td>\n",
       "      <td>0.882992</td>\n",
       "      <td>0.881321</td>\n",
       "      <td>0.883828</td>\n",
       "      <td>0.883828</td>\n",
       "      <td>0.883066</td>\n",
       "      <td>0.000927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.962106</td>\n",
       "      <td>0.192693</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>13</td>\n",
       "      <td>{'hidden_layer_sizes': 13}</td>\n",
       "      <td>0.873122</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>0.861204</td>\n",
       "      <td>0.867893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865929</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>13</td>\n",
       "      <td>0.876672</td>\n",
       "      <td>0.880903</td>\n",
       "      <td>0.877977</td>\n",
       "      <td>0.880903</td>\n",
       "      <td>0.880485</td>\n",
       "      <td>0.879388</td>\n",
       "      <td>0.001741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.970964</td>\n",
       "      <td>0.170638</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>14</td>\n",
       "      <td>{'hidden_layer_sizes': 14}</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.857860</td>\n",
       "      <td>0.856187</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860913</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>18</td>\n",
       "      <td>0.880853</td>\n",
       "      <td>0.883410</td>\n",
       "      <td>0.882156</td>\n",
       "      <td>0.880067</td>\n",
       "      <td>0.882992</td>\n",
       "      <td>0.881896</td>\n",
       "      <td>0.001265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.143509</td>\n",
       "      <td>0.173834</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>15</td>\n",
       "      <td>{'hidden_layer_sizes': 15}</td>\n",
       "      <td>0.874791</td>\n",
       "      <td>0.861204</td>\n",
       "      <td>0.866221</td>\n",
       "      <td>0.867893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866263</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>12</td>\n",
       "      <td>0.877090</td>\n",
       "      <td>0.881321</td>\n",
       "      <td>0.882574</td>\n",
       "      <td>0.882156</td>\n",
       "      <td>0.884246</td>\n",
       "      <td>0.881477</td>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.921478</td>\n",
       "      <td>0.017878</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>16</td>\n",
       "      <td>{'hidden_layer_sizes': 16}</td>\n",
       "      <td>0.869783</td>\n",
       "      <td>0.856187</td>\n",
       "      <td>0.864548</td>\n",
       "      <td>0.866221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864258</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>15</td>\n",
       "      <td>0.880017</td>\n",
       "      <td>0.885917</td>\n",
       "      <td>0.882156</td>\n",
       "      <td>0.882156</td>\n",
       "      <td>0.880903</td>\n",
       "      <td>0.882230</td>\n",
       "      <td>0.002013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.017724</td>\n",
       "      <td>0.018899</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>17</td>\n",
       "      <td>{'hidden_layer_sizes': 17}</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.861204</td>\n",
       "      <td>0.857860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860244</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>19</td>\n",
       "      <td>0.881271</td>\n",
       "      <td>0.883828</td>\n",
       "      <td>0.883410</td>\n",
       "      <td>0.888842</td>\n",
       "      <td>0.882574</td>\n",
       "      <td>0.883985</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.951211</td>\n",
       "      <td>0.060882</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>18</td>\n",
       "      <td>{'hidden_layer_sizes': 18}</td>\n",
       "      <td>0.864775</td>\n",
       "      <td>0.854515</td>\n",
       "      <td>0.867893</td>\n",
       "      <td>0.862876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862587</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>17</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.884246</td>\n",
       "      <td>0.883828</td>\n",
       "      <td>0.884246</td>\n",
       "      <td>0.887171</td>\n",
       "      <td>0.885072</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.872631</td>\n",
       "      <td>0.067307</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>19</td>\n",
       "      <td>{'hidden_layer_sizes': 19}</td>\n",
       "      <td>0.866444</td>\n",
       "      <td>0.861204</td>\n",
       "      <td>0.862876</td>\n",
       "      <td>0.862876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864593</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>14</td>\n",
       "      <td>0.882525</td>\n",
       "      <td>0.884664</td>\n",
       "      <td>0.881321</td>\n",
       "      <td>0.882156</td>\n",
       "      <td>0.884664</td>\n",
       "      <td>0.883066</td>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.002781      0.000243         0.000596        0.000199   \n",
       "1        0.219649      0.147265         0.001402        0.000205   \n",
       "2        0.119757      0.045211         0.001300        0.000403   \n",
       "3        0.229769      0.090151         0.001394        0.000368   \n",
       "4        0.429395      0.127031         0.001094        0.000198   \n",
       "5        0.637211      0.256696         0.001502        0.000012   \n",
       "6        0.644090      0.035931         0.000794        0.000243   \n",
       "7        0.808015      0.182203         0.001417        0.000384   \n",
       "8        0.788429      0.235601         0.001537        0.000642   \n",
       "9        0.820932      0.110276         0.001418        0.000412   \n",
       "10       0.929621      0.201192         0.001302        0.000249   \n",
       "11       0.941068      0.198130         0.001501        0.000318   \n",
       "12       0.962106      0.192693         0.001101        0.000198   \n",
       "13       0.970964      0.170638         0.001110        0.000212   \n",
       "14       1.143509      0.173834         0.001103        0.000382   \n",
       "15       0.921478      0.017878         0.001196        0.000244   \n",
       "16       1.017724      0.018899         0.000896        0.000200   \n",
       "17       0.951211      0.060882         0.000697        0.000246   \n",
       "18       0.872631      0.067307         0.000602        0.000202   \n",
       "\n",
       "   param_hidden_layer_sizes                      params  split0_test_score  \\\n",
       "0                         1   {'hidden_layer_sizes': 1}           0.873122   \n",
       "1                         2   {'hidden_layer_sizes': 2}           0.873122   \n",
       "2                         3   {'hidden_layer_sizes': 3}           0.873122   \n",
       "3                         4   {'hidden_layer_sizes': 4}           0.873122   \n",
       "4                         5   {'hidden_layer_sizes': 5}           0.874791   \n",
       "5                         6   {'hidden_layer_sizes': 6}           0.874791   \n",
       "6                         7   {'hidden_layer_sizes': 7}           0.871452   \n",
       "7                         8   {'hidden_layer_sizes': 8}           0.876461   \n",
       "8                         9   {'hidden_layer_sizes': 9}           0.873122   \n",
       "9                        10  {'hidden_layer_sizes': 10}           0.874791   \n",
       "10                       11  {'hidden_layer_sizes': 11}           0.869783   \n",
       "11                       12  {'hidden_layer_sizes': 12}           0.868114   \n",
       "12                       13  {'hidden_layer_sizes': 13}           0.873122   \n",
       "13                       14  {'hidden_layer_sizes': 14}           0.871452   \n",
       "14                       15  {'hidden_layer_sizes': 15}           0.874791   \n",
       "15                       16  {'hidden_layer_sizes': 16}           0.869783   \n",
       "16                       17  {'hidden_layer_sizes': 17}           0.871452   \n",
       "17                       18  {'hidden_layer_sizes': 18}           0.864775   \n",
       "18                       19  {'hidden_layer_sizes': 19}           0.866444   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0            0.874582           0.874582           0.872910  ...   \n",
       "1            0.874582           0.874582           0.872910  ...   \n",
       "2            0.872910           0.872910           0.872910  ...   \n",
       "3            0.871237           0.874582           0.872910  ...   \n",
       "4            0.864548           0.871237           0.866221  ...   \n",
       "5            0.867893           0.871237           0.866221  ...   \n",
       "6            0.869565           0.867893           0.862876  ...   \n",
       "7            0.871237           0.869565           0.869565  ...   \n",
       "8            0.867893           0.871237           0.866221  ...   \n",
       "9            0.866221           0.872910           0.869565  ...   \n",
       "10           0.874582           0.859532           0.862876  ...   \n",
       "11           0.864548           0.859532           0.861204  ...   \n",
       "12           0.859532           0.861204           0.867893  ...   \n",
       "13           0.857860           0.856187           0.859532  ...   \n",
       "14           0.861204           0.866221           0.867893  ...   \n",
       "15           0.856187           0.864548           0.866221  ...   \n",
       "16           0.847826           0.861204           0.857860  ...   \n",
       "17           0.854515           0.867893           0.862876  ...   \n",
       "18           0.861204           0.862876           0.862876  ...   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0          0.873621        0.000788                1            0.873746   \n",
       "1          0.873287        0.001243                2            0.873746   \n",
       "2          0.872952        0.000085                3            0.875000   \n",
       "3          0.871949        0.002289                4            0.873746   \n",
       "4          0.869942        0.003923                9            0.875836   \n",
       "5          0.870276        0.002979                6            0.876672   \n",
       "6          0.866598        0.003924               11            0.875836   \n",
       "7          0.871613        0.002537                5            0.877926   \n",
       "8          0.869942        0.002511                8            0.875418   \n",
       "9          0.870276        0.003161                7            0.877090   \n",
       "10         0.867268        0.005371               10            0.876254   \n",
       "11         0.863589        0.002982               16            0.883361   \n",
       "12         0.865929        0.004954               13            0.876672   \n",
       "13         0.860913        0.005414               18            0.880853   \n",
       "14         0.866263        0.005031               12            0.877090   \n",
       "15         0.864258        0.004465               15            0.880017   \n",
       "16         0.860244        0.007660               19            0.881271   \n",
       "17         0.862587        0.004433               17            0.885870   \n",
       "18         0.864593        0.003018               14            0.882525   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0             0.873381            0.873381            0.873799   \n",
       "1             0.873381            0.874216            0.874634   \n",
       "2             0.873799            0.875888            0.876306   \n",
       "3             0.878395            0.873381            0.874634   \n",
       "4             0.879649            0.877142            0.875052   \n",
       "5             0.876306            0.877977            0.876724   \n",
       "6             0.876724            0.877977            0.878395   \n",
       "7             0.874634            0.878813            0.879231   \n",
       "8             0.878395            0.877142            0.877142   \n",
       "9             0.877977            0.879231            0.877977   \n",
       "10            0.881738            0.879649            0.878395   \n",
       "11            0.882992            0.881321            0.883828   \n",
       "12            0.880903            0.877977            0.880903   \n",
       "13            0.883410            0.882156            0.880067   \n",
       "14            0.881321            0.882574            0.882156   \n",
       "15            0.885917            0.882156            0.882156   \n",
       "16            0.883828            0.883410            0.888842   \n",
       "17            0.884246            0.883828            0.884246   \n",
       "18            0.884664            0.881321            0.882156   \n",
       "\n",
       "    split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.873799          0.873621         0.000197  \n",
       "1             0.875888          0.874373         0.000868  \n",
       "2             0.873799          0.874958         0.001037  \n",
       "3             0.874634          0.874958         0.001788  \n",
       "4             0.875470          0.876630         0.001664  \n",
       "5             0.877560          0.877048         0.000620  \n",
       "6             0.879649          0.877716         0.001325  \n",
       "7             0.877977          0.877717         0.001619  \n",
       "8             0.879649          0.877549         0.001414  \n",
       "9             0.879649          0.878385         0.000930  \n",
       "10            0.877142          0.878636         0.001930  \n",
       "11            0.883828          0.883066         0.000927  \n",
       "12            0.880485          0.879388         0.001741  \n",
       "13            0.882992          0.881896         0.001265  \n",
       "14            0.884246          0.881477         0.002392  \n",
       "15            0.880903          0.882230         0.002013  \n",
       "16            0.882574          0.883985         0.002581  \n",
       "17            0.887171          0.885072         0.001261  \n",
       "18            0.884664          0.883066         0.001362  \n",
       "\n",
       "[19 rows x 21 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [i for i in range(1,20)] \n",
    "}\n",
    "gridSearch = GridSearchCV(MLPClassifier(activation='relu', solver='lbfgs', random_state=1, max_iter=1000), \n",
    "                          param_grid, cv=5, n_jobs=-1, return_train_score=True)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print('Best score: ', gridSearch.best_score_)\n",
    "print('Best parameters: ', gridSearch.best_params_)\n",
    "pd.DataFrame(data=gridSearch.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Car Sales.\n",
    "\n",
    "Consider the data on used cars (_ToyotaCorolla.csv_) with 1436 records and details on 38 attributes, including Price, Age, KM, HP, and other specifcations. The goal is to predict the price of a used Toyota Corolla based on its specifcations. You will need <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\">sklearn.neural_network.MLPRegressor</a> so review this documentation first. Try both ‘logistic’ and ‘relu’ activation functions for the hidden layer.<p>\n",
    "__a.__ Fit a neural network model to the data. Use a single hidden layer with 2 nodes. Use predictors Age_08_04, KM, Fuel_Type, HP, Automatic, Doors, Quarterly_Tax, Mfr_Guarantee, Guarantee_Period, Airco, Automatic_airco, CD_Player, Powered_Windows, Sport_Model, and Tow_Bar. Use the scikit-learn transformer _MinMaxScaler()_ to scale numerical variables to the range [0, 1]. Use separate transformer for the input and output data. Try both ‘logistic’ and ‘relu’ activation functions for the hidden layer.<p>\n",
    "<pre>    \n",
    "# Use the training data to learn the transformation (see Table 7.2 in DMBA) rescaling the entire data (numerical variables only) to [0, 1]. \n",
    "scaleInput = MinMaxScaler(feature_range=(0, 1), clip=True)\n",
    "scaleOutput = MinMaxScaler(feature_range=(0, 1), clip=True)\n",
    "# clip=True to clip transformed values of held-out data to provided feature range\n",
    "# Do not scale binary dummy variables.\n",
    "</pre>\n",
    "<p>    \n",
    "To create the dummy variables, use the pandas function pd.get_dummies(). Record the RMS error for the training data and the validation data. Repeat the process, changing the number of hidden layers and nodes to {single layer with 5 nodes}, {two layers, 5 nodes in each layer}.\n",
    "<p>\n",
    "    \n",
    "<pre>\n",
    "From the textbook: \"Using the Output for Prediction and Classification - When the neural network is used for predicting a numerical outcome variable, MLPRegressor() uses an identity activation function (i.e., no activation function). Both predictor and outcome variables should be scaled to a [0, 1] interval before training the network. The output will therefore also be on a [0, 1] scale. To transform the prediction back to the original y units, which were in the range [a, b], we multiply the network output by (b − a) and add a.\"\n",
    "To transform the prediction back to the original y units, use <a href=\"https://stackoverflow.com/questions/59771061/using-inverse-transform-minmaxscaler-from-scikit-learn-to-force-a-dataframe-be-i\">inverse_transform</a>.\n",
    "\n",
    "Example:\n",
    "\n",
    "#Create new data\n",
    "new_data = pd.DataFrame(np.array([[8,20],[11,2],[5,3]]))\n",
    "new_data\n",
    "\n",
    "# Create a Scaler for the new data\n",
    "scaler_new_data = MinMaxScaler() \n",
    "# Trasform new data in the [0-1] range\n",
    "scaled_new_data = scaler_new_data.fit_transform(new_data)\n",
    "scaled_new_data\n",
    "\n",
    "# Inverse transform new data from [0-1] to [min, max] of data\n",
    "inver_new_data = scaler_new_data.inverse_transform(scaled_new_data)\n",
    "inver_new_data\n",
    "\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "car_df = pd.read_csv(DATA / 'ToyotaCorolla.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Model</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>...</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Power_Steering</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Parking_Assistant</th>\n",
       "      <th>Tow_Bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2002</td>\n",
       "      <td>41711</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>48000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>38500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                          Model  Price  Age_08_04  \\\n",
       "0   1  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13500         23   \n",
       "1   2  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13750         23   \n",
       "2   3  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13950         24   \n",
       "3   4  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  14950         26   \n",
       "4   5    TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors  13750         30   \n",
       "\n",
       "   Mfg_Month  Mfg_Year     KM Fuel_Type  HP  Met_Color  ... Powered_Windows  \\\n",
       "0         10      2002  46986    Diesel  90          1  ...               1   \n",
       "1         10      2002  72937    Diesel  90          1  ...               0   \n",
       "2          9      2002  41711    Diesel  90          1  ...               0   \n",
       "3          7      2002  48000    Diesel  90          0  ...               0   \n",
       "4          3      2002  38500    Diesel  90          0  ...               1   \n",
       "\n",
       "   Power_Steering  Radio  Mistlamps  Sport_Model  Backseat_Divider  \\\n",
       "0               1      0          0            0                 1   \n",
       "1               1      0          0            0                 1   \n",
       "2               1      0          0            0                 1   \n",
       "3               1      0          0            0                 1   \n",
       "4               1      0          1            0                 1   \n",
       "\n",
       "   Metallic_Rim  Radio_cassette  Parking_Assistant  Tow_Bar  \n",
       "0             0               0                  0        0  \n",
       "1             0               0                  0        0  \n",
       "2             0               0                  0        0  \n",
       "3             0               0                  0        0  \n",
       "4             0               0                  0        0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired = ['Price', 'Age_08_04', 'KM', 'Fuel_Type', 'HP', 'Automatic', 'Doors', 'Quarterly_Tax', 'Mfr_Guarantee', 'Guarantee_Period', 'Airco', 'Automatic_airco', 'CD_Player', 'Powered_Windows', 'Sport_Model', 'Tow_Bar']\n",
    "predictors = ['Age_08_04', 'KM', 'Fuel_Type', 'HP', 'Automatic', 'Doors', 'Quarterly_Tax', 'Mfr_Guarantee', 'Guarantee_Period', 'Airco', 'Automatic_airco', 'CD_Player', 'Powered_Windows', 'Sport_Model', 'Tow_Bar']\n",
    "outcome = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>KM</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>HP</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Quarterly_Tax</th>\n",
       "      <th>Mfr_Guarantee</th>\n",
       "      <th>Guarantee_Period</th>\n",
       "      <th>Airco</th>\n",
       "      <th>Automatic_airco</th>\n",
       "      <th>CD_Player</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Tow_Bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>46986</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>72937</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>41711</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>48000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>38500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Age_08_04     KM Fuel_Type  HP  Automatic  Doors  Quarterly_Tax  \\\n",
       "0  13500         23  46986    Diesel  90          0      3            210   \n",
       "1  13750         23  72937    Diesel  90          0      3            210   \n",
       "2  13950         24  41711    Diesel  90          0      3            210   \n",
       "3  14950         26  48000    Diesel  90          0      3            210   \n",
       "4  13750         30  38500    Diesel  90          0      3            210   \n",
       "\n",
       "   Mfr_Guarantee  Guarantee_Period  Airco  Automatic_airco  CD_Player  \\\n",
       "0              0                 3      0                0          0   \n",
       "1              0                 3      1                0          1   \n",
       "2              1                 3      0                0          0   \n",
       "3              1                 3      0                0          0   \n",
       "4              1                 3      1                0          0   \n",
       "\n",
       "   Powered_Windows  Sport_Model  Tow_Bar  \n",
       "0                1            0        0  \n",
       "1                0            0        0  \n",
       "2                0            0        0  \n",
       "3                0            0        0  \n",
       "4                1            0        0  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df = car_df[desired]\n",
    "car_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Automatic_airco\n",
       "0    1355\n",
       "1      81\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df.Automatic_airco.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price                int64\n",
       "Age_08_04            int64\n",
       "KM                   int64\n",
       "Fuel_Type           object\n",
       "HP                   int64\n",
       "Automatic            int64\n",
       "Doors                int64\n",
       "Quarterly_Tax        int64\n",
       "Mfr_Guarantee        int64\n",
       "Guarantee_Period     int64\n",
       "Airco                int64\n",
       "Automatic_airco      int64\n",
       "CD_Player            int64\n",
       "Powered_Windows      int64\n",
       "Sport_Model          int64\n",
       "Tow_Bar              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                  int64\n",
      "Age_08_04              int64\n",
      "KM                     int64\n",
      "Fuel_Type           category\n",
      "HP                     int64\n",
      "Automatic           category\n",
      "Doors                  uint8\n",
      "Quarterly_Tax          int64\n",
      "Mfr_Guarantee          uint8\n",
      "Guarantee_Period    category\n",
      "Airco                  uint8\n",
      "Automatic_airco        uint8\n",
      "CD_Player              uint8\n",
      "Powered_Windows        uint8\n",
      "Sport_Model            uint8\n",
      "Tow_Bar                uint8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "car_df['Fuel_Type'] = car_df['Fuel_Type'].astype('category')\n",
    "car_df['Automatic'] = car_df['Automatic'].astype('category')\n",
    "car_df['Doors'] = car_df['Doors'].astype('uint8')\n",
    "car_df['Mfr_Guarantee'] = car_df['Mfr_Guarantee'].astype('uint8')\n",
    "car_df['Airco'] = car_df['Airco'].astype('uint8')\n",
    "car_df['Guarantee_Period'] = car_df['Guarantee_Period'].astype('category')\n",
    "car_df['Automatic_airco'] = car_df['Automatic_airco'].astype('uint8')\n",
    "car_df['CD_Player'] = car_df['CD_Player'].astype('uint8')\n",
    "car_df['Powered_Windows'] = car_df['Powered_Windows'].astype('uint8')\n",
    "car_df['Sport_Model'] = car_df['Sport_Model'].astype('uint8')\n",
    "car_df['Tow_Bar'] = car_df['Tow_Bar'].astype('uint8')\n",
    "print(car_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df_dum = pd.get_dummies(data=car_df, drop_first=True, prefix_sep='_', dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Quarterly_Tax</th>\n",
       "      <th>Mfr_Guarantee</th>\n",
       "      <th>Airco</th>\n",
       "      <th>Automatic_airco</th>\n",
       "      <th>CD_Player</th>\n",
       "      <th>...</th>\n",
       "      <th>Fuel_Type_Petrol</th>\n",
       "      <th>Automatic_1</th>\n",
       "      <th>Guarantee_Period_6</th>\n",
       "      <th>Guarantee_Period_12</th>\n",
       "      <th>Guarantee_Period_13</th>\n",
       "      <th>Guarantee_Period_18</th>\n",
       "      <th>Guarantee_Period_20</th>\n",
       "      <th>Guarantee_Period_24</th>\n",
       "      <th>Guarantee_Period_28</th>\n",
       "      <th>Guarantee_Period_36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>46986</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>72937</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>41711</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>48000</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>38500</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>7500</td>\n",
       "      <td>69</td>\n",
       "      <td>20544</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>10845</td>\n",
       "      <td>72</td>\n",
       "      <td>19000</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>8500</td>\n",
       "      <td>71</td>\n",
       "      <td>17016</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>7250</td>\n",
       "      <td>70</td>\n",
       "      <td>16916</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>6950</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1436 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price  Age_08_04     KM   HP  Doors  Quarterly_Tax  Mfr_Guarantee  \\\n",
       "0     13500         23  46986   90      3            210              0   \n",
       "1     13750         23  72937   90      3            210              0   \n",
       "2     13950         24  41711   90      3            210              1   \n",
       "3     14950         26  48000   90      3            210              1   \n",
       "4     13750         30  38500   90      3            210              1   \n",
       "...     ...        ...    ...  ...    ...            ...            ...   \n",
       "1431   7500         69  20544   86      3             69              1   \n",
       "1432  10845         72  19000   86      3             69              0   \n",
       "1433   8500         71  17016   86      3             69              0   \n",
       "1434   7250         70  16916   86      3             69              1   \n",
       "1435   6950         76      1  110      5             19              0   \n",
       "\n",
       "      Airco  Automatic_airco  CD_Player  ...  Fuel_Type_Petrol  Automatic_1  \\\n",
       "0         0                0          0  ...                 0            0   \n",
       "1         1                0          1  ...                 0            0   \n",
       "2         0                0          0  ...                 0            0   \n",
       "3         0                0          0  ...                 0            0   \n",
       "4         1                0          0  ...                 0            0   \n",
       "...     ...              ...        ...  ...               ...          ...   \n",
       "1431      1                0          0  ...                 1            0   \n",
       "1432      0                0          0  ...                 1            0   \n",
       "1433      0                0          0  ...                 1            0   \n",
       "1434      0                0          0  ...                 1            0   \n",
       "1435      0                0          0  ...                 1            0   \n",
       "\n",
       "      Guarantee_Period_6  Guarantee_Period_12  Guarantee_Period_13  \\\n",
       "0                      0                    0                    0   \n",
       "1                      0                    0                    0   \n",
       "2                      0                    0                    0   \n",
       "3                      0                    0                    0   \n",
       "4                      0                    0                    0   \n",
       "...                  ...                  ...                  ...   \n",
       "1431                   0                    0                    0   \n",
       "1432                   0                    0                    0   \n",
       "1433                   0                    0                    0   \n",
       "1434                   0                    0                    0   \n",
       "1435                   0                    0                    0   \n",
       "\n",
       "      Guarantee_Period_18  Guarantee_Period_20  Guarantee_Period_24  \\\n",
       "0                       0                    0                    0   \n",
       "1                       0                    0                    0   \n",
       "2                       0                    0                    0   \n",
       "3                       0                    0                    0   \n",
       "4                       0                    0                    0   \n",
       "...                   ...                  ...                  ...   \n",
       "1431                    0                    0                    0   \n",
       "1432                    0                    0                    0   \n",
       "1433                    0                    0                    0   \n",
       "1434                    0                    0                    0   \n",
       "1435                    0                    0                    0   \n",
       "\n",
       "      Guarantee_Period_28  Guarantee_Period_36  \n",
       "0                       0                    0  \n",
       "1                       0                    0  \n",
       "2                       0                    0  \n",
       "3                       0                    0  \n",
       "4                       0                    0  \n",
       "...                   ...                  ...  \n",
       "1431                    0                    0  \n",
       "1432                    0                    0  \n",
       "1433                    0                    0  \n",
       "1434                    0                    0  \n",
       "1435                    0                    0  \n",
       "\n",
       "[1436 rows x 24 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_dum = car_df_dum.drop(columns=outcome).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Quarterly_Tax</th>\n",
       "      <th>Mfr_Guarantee</th>\n",
       "      <th>Airco</th>\n",
       "      <th>Automatic_airco</th>\n",
       "      <th>CD_Player</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>...</th>\n",
       "      <th>Fuel_Type_Petrol</th>\n",
       "      <th>Automatic_1</th>\n",
       "      <th>Guarantee_Period_6</th>\n",
       "      <th>Guarantee_Period_12</th>\n",
       "      <th>Guarantee_Period_13</th>\n",
       "      <th>Guarantee_Period_18</th>\n",
       "      <th>Guarantee_Period_20</th>\n",
       "      <th>Guarantee_Period_24</th>\n",
       "      <th>Guarantee_Period_28</th>\n",
       "      <th>Guarantee_Period_36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>75</td>\n",
       "      <td>82256</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>79</td>\n",
       "      <td>131500</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>61</td>\n",
       "      <td>102106</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>50</td>\n",
       "      <td>22648</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>68</td>\n",
       "      <td>117000</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>62</td>\n",
       "      <td>90000</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>65</td>\n",
       "      <td>59000</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>75</td>\n",
       "      <td>125400</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>38</td>\n",
       "      <td>60829</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>78</td>\n",
       "      <td>161775</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>861 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age_08_04      KM   HP  Doors  Quarterly_Tax  Mfr_Guarantee  Airco  \\\n",
       "1238         75   82256  110      3             69              0      0   \n",
       "1085         79  131500   72      5            185              0      1   \n",
       "680          61  102106  110      3             69              0      1   \n",
       "593          50   22648   97      5             85              0      0   \n",
       "647          68  117000   72      3            185              0      0   \n",
       "...         ...     ...  ...    ...            ...            ...    ...   \n",
       "715          62   90000  110      3             69              0      0   \n",
       "905          65   59000  110      3             69              0      0   \n",
       "1096         75  125400  110      3             69              0      0   \n",
       "235          38   60829  110      5             85              1      0   \n",
       "1061         78  161775   86      3             69              0      0   \n",
       "\n",
       "      Automatic_airco  CD_Player  Powered_Windows  ...  Fuel_Type_Petrol  \\\n",
       "1238                0          0                1  ...                 1   \n",
       "1085                0          0                1  ...                 0   \n",
       "680                 0          0                1  ...                 1   \n",
       "593                 0          0                1  ...                 1   \n",
       "647                 0          0                0  ...                 0   \n",
       "...               ...        ...              ...  ...               ...   \n",
       "715                 0          0                0  ...                 1   \n",
       "905                 0          0                0  ...                 1   \n",
       "1096                0          0                1  ...                 1   \n",
       "235                 0          0                0  ...                 1   \n",
       "1061                0          0                1  ...                 1   \n",
       "\n",
       "      Automatic_1  Guarantee_Period_6  Guarantee_Period_12  \\\n",
       "1238            0                   0                    0   \n",
       "1085            0                   0                    0   \n",
       "680             0                   0                    0   \n",
       "593             0                   0                    0   \n",
       "647             0                   0                    0   \n",
       "...           ...                 ...                  ...   \n",
       "715             0                   0                    0   \n",
       "905             0                   0                    0   \n",
       "1096            0                   1                    0   \n",
       "235             0                   0                    0   \n",
       "1061            0                   0                    0   \n",
       "\n",
       "      Guarantee_Period_13  Guarantee_Period_18  Guarantee_Period_20  \\\n",
       "1238                    0                    0                    0   \n",
       "1085                    0                    0                    0   \n",
       "680                     0                    0                    0   \n",
       "593                     0                    0                    0   \n",
       "647                     0                    0                    0   \n",
       "...                   ...                  ...                  ...   \n",
       "715                     0                    0                    0   \n",
       "905                     0                    0                    0   \n",
       "1096                    0                    0                    0   \n",
       "235                     0                    0                    0   \n",
       "1061                    0                    0                    0   \n",
       "\n",
       "      Guarantee_Period_24  Guarantee_Period_28  Guarantee_Period_36  \n",
       "1238                    0                    0                    0  \n",
       "1085                    0                    0                    0  \n",
       "680                     0                    0                    0  \n",
       "593                     0                    0                    0  \n",
       "647                     0                    0                    0  \n",
       "...                   ...                  ...                  ...  \n",
       "715                     0                    0                    0  \n",
       "905                     0                    0                    0  \n",
       "1096                    0                    0                    0  \n",
       "235                     0                    0                    0  \n",
       "1061                    0                    0                    0  \n",
       "\n",
       "[861 rows x 23 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = car_df_dum[predictors_dum]\n",
    "y = car_df_dum[outcome]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Quarterly_Tax</th>\n",
       "      <th>Mfr_Guarantee</th>\n",
       "      <th>Airco</th>\n",
       "      <th>Automatic_airco</th>\n",
       "      <th>CD_Player</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>...</th>\n",
       "      <th>Fuel_Type_Petrol</th>\n",
       "      <th>Automatic_1</th>\n",
       "      <th>Guarantee_Period_6</th>\n",
       "      <th>Guarantee_Period_12</th>\n",
       "      <th>Guarantee_Period_13</th>\n",
       "      <th>Guarantee_Period_18</th>\n",
       "      <th>Guarantee_Period_20</th>\n",
       "      <th>Guarantee_Period_24</th>\n",
       "      <th>Guarantee_Period_28</th>\n",
       "      <th>Guarantee_Period_36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.353118</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.564521</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.438334</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.097223</td>\n",
       "      <td>0.227642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.502273</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.386363</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.253281</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.538334</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.261133</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.694491</td>\n",
       "      <td>0.138211</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>861 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age_08_04        KM        HP     Doors  Quarterly_Tax  Mfr_Guarantee  \\\n",
       "0     0.936709  0.353118  0.333333  0.333333       0.189394            0.0   \n",
       "1     0.987342  0.564521  0.024390  1.000000       0.628788            0.0   \n",
       "2     0.759494  0.438334  0.333333  0.333333       0.189394            0.0   \n",
       "3     0.620253  0.097223  0.227642  1.000000       0.250000            0.0   \n",
       "4     0.848101  0.502273  0.024390  0.333333       0.628788            0.0   \n",
       "..         ...       ...       ...       ...            ...            ...   \n",
       "856   0.772152  0.386363  0.333333  0.333333       0.189394            0.0   \n",
       "857   0.810127  0.253281  0.333333  0.333333       0.189394            0.0   \n",
       "858   0.936709  0.538334  0.333333  0.333333       0.189394            0.0   \n",
       "859   0.468354  0.261133  0.333333  1.000000       0.250000            1.0   \n",
       "860   0.974684  0.694491  0.138211  0.333333       0.189394            0.0   \n",
       "\n",
       "     Airco  Automatic_airco  CD_Player  Powered_Windows  ...  \\\n",
       "0      0.0              0.0        0.0              1.0  ...   \n",
       "1      1.0              0.0        0.0              1.0  ...   \n",
       "2      1.0              0.0        0.0              1.0  ...   \n",
       "3      0.0              0.0        0.0              1.0  ...   \n",
       "4      0.0              0.0        0.0              0.0  ...   \n",
       "..     ...              ...        ...              ...  ...   \n",
       "856    0.0              0.0        0.0              0.0  ...   \n",
       "857    0.0              0.0        0.0              0.0  ...   \n",
       "858    0.0              0.0        0.0              1.0  ...   \n",
       "859    0.0              0.0        0.0              0.0  ...   \n",
       "860    0.0              0.0        0.0              1.0  ...   \n",
       "\n",
       "     Fuel_Type_Petrol  Automatic_1  Guarantee_Period_6  Guarantee_Period_12  \\\n",
       "0                 1.0          0.0                 0.0                  0.0   \n",
       "1                 0.0          0.0                 0.0                  0.0   \n",
       "2                 1.0          0.0                 0.0                  0.0   \n",
       "3                 1.0          0.0                 0.0                  0.0   \n",
       "4                 0.0          0.0                 0.0                  0.0   \n",
       "..                ...          ...                 ...                  ...   \n",
       "856               1.0          0.0                 0.0                  0.0   \n",
       "857               1.0          0.0                 0.0                  0.0   \n",
       "858               1.0          0.0                 1.0                  0.0   \n",
       "859               1.0          0.0                 0.0                  0.0   \n",
       "860               1.0          0.0                 0.0                  0.0   \n",
       "\n",
       "     Guarantee_Period_13  Guarantee_Period_18  Guarantee_Period_20  \\\n",
       "0                    0.0                  0.0                  0.0   \n",
       "1                    0.0                  0.0                  0.0   \n",
       "2                    0.0                  0.0                  0.0   \n",
       "3                    0.0                  0.0                  0.0   \n",
       "4                    0.0                  0.0                  0.0   \n",
       "..                   ...                  ...                  ...   \n",
       "856                  0.0                  0.0                  0.0   \n",
       "857                  0.0                  0.0                  0.0   \n",
       "858                  0.0                  0.0                  0.0   \n",
       "859                  0.0                  0.0                  0.0   \n",
       "860                  0.0                  0.0                  0.0   \n",
       "\n",
       "     Guarantee_Period_24  Guarantee_Period_28  Guarantee_Period_36  \n",
       "0                    0.0                  0.0                  0.0  \n",
       "1                    0.0                  0.0                  0.0  \n",
       "2                    0.0                  0.0                  0.0  \n",
       "3                    0.0                  0.0                  0.0  \n",
       "4                    0.0                  0.0                  0.0  \n",
       "..                   ...                  ...                  ...  \n",
       "856                  0.0                  0.0                  0.0  \n",
       "857                  0.0                  0.0                  0.0  \n",
       "858                  0.0                  0.0                  0.0  \n",
       "859                  0.0                  0.0                  0.0  \n",
       "860                  0.0                  0.0                  0.0  \n",
       "\n",
       "[861 rows x 23 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaleInput = MinMaxScaler(feature_range=(0,1),clip=True)\n",
    "train_X = pd.DataFrame(scaleInput.fit_transform(train_X),columns=train_X.columns)\n",
    "valid_X = pd.DataFrame(scaleInput.fit_transform(valid_X),columns=valid_X.columns)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(5, 1), max_iter=10000,\n",
       "             random_state=1, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(5, 1), max_iter=10000,\n",
       "             random_state=1, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='logistic', hidden_layer_sizes=(5, 1), max_iter=10000,\n",
       "             random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train neural network with 1 layer and 5 hidden nodes and logistic\n",
    "MLPR_Logi = MLPRegressor(hidden_layer_sizes=(5,1), activation='logistic', solver='lbfgs', random_state=1, max_iter=10000)\n",
    "MLPR_Logi.fit(train_X, train_y.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 3706.3834\n",
      "            Mean Absolute Error (MAE) : 2676.2223\n",
      "          Mean Percentage Error (MPE) : -9.3699\n",
      "Mean Absolute Percentage Error (MAPE) : 24.8734\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(train_y, MLPR_Logi.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -108.2090\n",
      "       Root Mean Squared Error (RMSE) : 3502.0841\n",
      "            Mean Absolute Error (MAE) : 2572.1954\n",
      "          Mean Percentage Error (MPE) : -10.0617\n",
      "Mean Absolute Percentage Error (MAPE) : 24.7515\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(valid_y, MLPR_Logi.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(5, 1), max_iter=10000, random_state=1,\n",
       "             solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(5, 1), max_iter=10000, random_state=1,\n",
       "             solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(5, 1), max_iter=10000, random_state=1,\n",
       "             solver='lbfgs')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train neural network with 1 layer and 5 hidden nodes and relu\n",
    "MLPR_Relu = MLPRegressor(hidden_layer_sizes=(5,1), activation='relu', solver='lbfgs', random_state=1, max_iter=10000)\n",
    "MLPR_Relu.fit(train_X, train_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 3706.3834\n",
      "            Mean Absolute Error (MAE) : 2676.2223\n",
      "          Mean Percentage Error (MPE) : -9.3699\n",
      "Mean Absolute Percentage Error (MAPE) : 24.8734\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(train_y, MLPR_Relu.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -108.2090\n",
      "       Root Mean Squared Error (RMSE) : 3502.0841\n",
      "            Mean Absolute Error (MAE) : 2572.1954\n",
      "          Mean Percentage Error (MPE) : -10.0617\n",
      "Mean Absolute Percentage Error (MAPE) : 24.7515\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(valid_y, MLPR_Relu.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(5, 2), max_iter=10000,\n",
       "             random_state=1, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(5, 2), max_iter=10000,\n",
       "             random_state=1, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='logistic', hidden_layer_sizes=(5, 2), max_iter=10000,\n",
       "             random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train neural network with 2 layer and 5 hidden nodes and logistic\n",
    "MLPR_Logi = MLPRegressor(hidden_layer_sizes=(5,2), activation='logistic', solver='lbfgs', random_state=1, max_iter=10000)\n",
    "MLPR_Logi.fit(train_X, train_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.0097\n",
      "       Root Mean Squared Error (RMSE) : 3706.3834\n",
      "            Mean Absolute Error (MAE) : 2676.2197\n",
      "          Mean Percentage Error (MPE) : -9.3698\n",
      "Mean Absolute Percentage Error (MAPE) : 24.8734\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(train_y, MLPR_Logi.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -108.1993\n",
      "       Root Mean Squared Error (RMSE) : 3502.0838\n",
      "            Mean Absolute Error (MAE) : 2572.1928\n",
      "          Mean Percentage Error (MPE) : -10.0616\n",
      "Mean Absolute Percentage Error (MAPE) : 24.7515\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(valid_y, MLPR_Logi.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(5, 2), max_iter=10000, random_state=1,\n",
       "             solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(5, 2), max_iter=10000, random_state=1,\n",
       "             solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(5, 2), max_iter=10000, random_state=1,\n",
       "             solver='lbfgs')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train neural network with 2 layer and 5 hidden nodes and relu\n",
    "MLPR_Relu = MLPRegressor(hidden_layer_sizes=(5,2), activation='relu', solver='lbfgs', random_state=1, max_iter=10000)\n",
    "MLPR_Relu.fit(train_X, train_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.0001\n",
      "       Root Mean Squared Error (RMSE) : 3706.3834\n",
      "            Mean Absolute Error (MAE) : 2676.2223\n",
      "          Mean Percentage Error (MPE) : -9.3699\n",
      "Mean Absolute Percentage Error (MAPE) : 24.8734\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(train_y, MLPR_Relu.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -108.2089\n",
      "       Root Mean Squared Error (RMSE) : 3502.0841\n",
      "            Mean Absolute Error (MAE) : 2572.1954\n",
      "          Mean Percentage Error (MPE) : -10.0617\n",
      "Mean Absolute Percentage Error (MAPE) : 24.7515\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(valid_y, MLPR_Relu.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(5, 5), max_iter=10000, random_state=1,\n",
       "             solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(5, 5), max_iter=10000, random_state=1,\n",
       "             solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(5, 5), max_iter=10000, random_state=1,\n",
       "             solver='lbfgs')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train neural network with 3 layer and 5 hidden nodes and relu\n",
    "MLPR_Relu = MLPRegressor(hidden_layer_sizes=(5,5), activation='relu', solver='lbfgs', random_state=1, max_iter=10000)\n",
    "MLPR_Relu.fit(train_X, train_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.3445\n",
      "       Root Mean Squared Error (RMSE) : 1043.4754\n",
      "            Mean Absolute Error (MAE) : 778.2537\n",
      "          Mean Percentage Error (MPE) : -1.0035\n",
      "Mean Absolute Percentage Error (MAPE) : 7.7110\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(train_y, MLPR_Relu.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -89.7188\n",
      "       Root Mean Squared Error (RMSE) : 1097.9499\n",
      "            Mean Absolute Error (MAE) : 837.5120\n",
      "          Mean Percentage Error (MPE) : -1.7068\n",
      "Mean Absolute Percentage Error (MAPE) : 8.4076\n"
     ]
    }
   ],
   "source": [
    "regressionSummary(valid_y, MLPR_Relu.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. What happens to the RMS error for the training data as the number of layers and nodes increases? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The RMS error stayed the sme for every layer and node increase. Though overall the data really stayed the same between the logistic and relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. What happens to the RMS error for the validation data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The RMS error went up slightly for every layer and node increase. Though overall the data really stayed the same between the logistic and relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Comment on the appropriate number of layers and nodes for this application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing the number of layers might decrease the RMS but it may create an over fitted result. The correct number of layers would have to be analyzed use CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b.__ Use GridSearchCV() to search for the number of nodes with the best score in a single layer of hidden nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.9013079976554469\n",
      "Best parameters:  {'hidden_layer_sizes': 13}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061173</td>\n",
       "      <td>0.050534</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>1</td>\n",
       "      <td>{'hidden_layer_sizes': 1}</td>\n",
       "      <td>0.804930</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>6.281043e-01</td>\n",
       "      <td>0.834395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776330</td>\n",
       "      <td>0.094136</td>\n",
       "      <td>17</td>\n",
       "      <td>0.813319</td>\n",
       "      <td>0.888642</td>\n",
       "      <td>6.828197e-01</td>\n",
       "      <td>8.636990e-01</td>\n",
       "      <td>0.782727</td>\n",
       "      <td>0.806241</td>\n",
       "      <td>0.072010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035286</td>\n",
       "      <td>0.023341</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>2</td>\n",
       "      <td>{'hidden_layer_sizes': 2}</td>\n",
       "      <td>0.871815</td>\n",
       "      <td>0.908073</td>\n",
       "      <td>-9.021308e-07</td>\n",
       "      <td>-0.002838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532584</td>\n",
       "      <td>0.436167</td>\n",
       "      <td>18</td>\n",
       "      <td>0.904814</td>\n",
       "      <td>0.896733</td>\n",
       "      <td>-4.440892e-15</td>\n",
       "      <td>-4.218847e-15</td>\n",
       "      <td>0.903874</td>\n",
       "      <td>0.541084</td>\n",
       "      <td>0.441802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042964</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>3</td>\n",
       "      <td>{'hidden_layer_sizes': 3}</td>\n",
       "      <td>0.865441</td>\n",
       "      <td>0.897130</td>\n",
       "      <td>8.867137e-01</td>\n",
       "      <td>0.874968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880169</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>13</td>\n",
       "      <td>0.896163</td>\n",
       "      <td>0.888663</td>\n",
       "      <td>8.938006e-01</td>\n",
       "      <td>8.953021e-01</td>\n",
       "      <td>0.894799</td>\n",
       "      <td>0.893746</td>\n",
       "      <td>0.002654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102883</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>4</td>\n",
       "      <td>{'hidden_layer_sizes': 4}</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.914900</td>\n",
       "      <td>8.889936e-01</td>\n",
       "      <td>0.906389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899402</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>2</td>\n",
       "      <td>0.928724</td>\n",
       "      <td>0.919772</td>\n",
       "      <td>9.295066e-01</td>\n",
       "      <td>9.256012e-01</td>\n",
       "      <td>0.925822</td>\n",
       "      <td>0.925885</td>\n",
       "      <td>0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>5</td>\n",
       "      <td>{'hidden_layer_sizes': 5}</td>\n",
       "      <td>0.875237</td>\n",
       "      <td>-0.029371</td>\n",
       "      <td>-9.024328e-07</td>\n",
       "      <td>0.882977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522945</td>\n",
       "      <td>0.439086</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.995204e-15</td>\n",
       "      <td>9.048456e-01</td>\n",
       "      <td>0.903875</td>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.443114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.081259</td>\n",
       "      <td>0.043442</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>6</td>\n",
       "      <td>{'hidden_layer_sizes': 6}</td>\n",
       "      <td>0.865394</td>\n",
       "      <td>0.897123</td>\n",
       "      <td>8.922768e-01</td>\n",
       "      <td>0.874962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888019</td>\n",
       "      <td>0.016010</td>\n",
       "      <td>12</td>\n",
       "      <td>0.896163</td>\n",
       "      <td>0.888663</td>\n",
       "      <td>9.260035e-01</td>\n",
       "      <td>8.953021e-01</td>\n",
       "      <td>0.921885</td>\n",
       "      <td>0.905603</td>\n",
       "      <td>0.015254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.187866</td>\n",
       "      <td>0.046103</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>7</td>\n",
       "      <td>{'hidden_layer_sizes': 7}</td>\n",
       "      <td>0.881704</td>\n",
       "      <td>0.916310</td>\n",
       "      <td>8.848166e-01</td>\n",
       "      <td>0.904719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895306</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>5</td>\n",
       "      <td>0.925483</td>\n",
       "      <td>0.930465</td>\n",
       "      <td>9.340075e-01</td>\n",
       "      <td>9.252127e-01</td>\n",
       "      <td>0.932478</td>\n",
       "      <td>0.929529</td>\n",
       "      <td>0.003595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.137570</td>\n",
       "      <td>0.055958</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>8</td>\n",
       "      <td>{'hidden_layer_sizes': 8}</td>\n",
       "      <td>0.868913</td>\n",
       "      <td>0.914378</td>\n",
       "      <td>8.902135e-01</td>\n",
       "      <td>0.902263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894286</td>\n",
       "      <td>0.015030</td>\n",
       "      <td>7</td>\n",
       "      <td>0.930957</td>\n",
       "      <td>0.924777</td>\n",
       "      <td>9.302323e-01</td>\n",
       "      <td>9.244407e-01</td>\n",
       "      <td>0.926575</td>\n",
       "      <td>0.927396</td>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.039279</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>9</td>\n",
       "      <td>{'hidden_layer_sizes': 9}</td>\n",
       "      <td>0.865427</td>\n",
       "      <td>0.897119</td>\n",
       "      <td>8.867123e-01</td>\n",
       "      <td>0.874973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880168</td>\n",
       "      <td>0.010836</td>\n",
       "      <td>14</td>\n",
       "      <td>0.896163</td>\n",
       "      <td>0.888663</td>\n",
       "      <td>8.938006e-01</td>\n",
       "      <td>8.953021e-01</td>\n",
       "      <td>0.894799</td>\n",
       "      <td>0.893746</td>\n",
       "      <td>0.002654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.145339</td>\n",
       "      <td>0.029413</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>10</td>\n",
       "      <td>{'hidden_layer_sizes': 10}</td>\n",
       "      <td>0.872870</td>\n",
       "      <td>0.912837</td>\n",
       "      <td>8.885163e-01</td>\n",
       "      <td>0.905346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897932</td>\n",
       "      <td>0.015111</td>\n",
       "      <td>3</td>\n",
       "      <td>0.930840</td>\n",
       "      <td>0.922817</td>\n",
       "      <td>9.287350e-01</td>\n",
       "      <td>9.236658e-01</td>\n",
       "      <td>0.921748</td>\n",
       "      <td>0.925561</td>\n",
       "      <td>0.003567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.158379</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>11</td>\n",
       "      <td>{'hidden_layer_sizes': 11}</td>\n",
       "      <td>0.877578</td>\n",
       "      <td>0.914986</td>\n",
       "      <td>8.934466e-01</td>\n",
       "      <td>0.891841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892323</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>8</td>\n",
       "      <td>0.930269</td>\n",
       "      <td>0.919113</td>\n",
       "      <td>9.258400e-01</td>\n",
       "      <td>9.230312e-01</td>\n",
       "      <td>0.929766</td>\n",
       "      <td>0.925604</td>\n",
       "      <td>0.004193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.263664</td>\n",
       "      <td>0.058515</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>12</td>\n",
       "      <td>{'hidden_layer_sizes': 12}</td>\n",
       "      <td>0.857073</td>\n",
       "      <td>0.910600</td>\n",
       "      <td>8.806527e-01</td>\n",
       "      <td>0.905348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888682</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>11</td>\n",
       "      <td>0.937404</td>\n",
       "      <td>0.927438</td>\n",
       "      <td>9.340613e-01</td>\n",
       "      <td>9.310227e-01</td>\n",
       "      <td>0.928853</td>\n",
       "      <td>0.931756</td>\n",
       "      <td>0.003601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.115281</td>\n",
       "      <td>0.043370</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>13</td>\n",
       "      <td>{'hidden_layer_sizes': 13}</td>\n",
       "      <td>0.884102</td>\n",
       "      <td>0.914332</td>\n",
       "      <td>8.934573e-01</td>\n",
       "      <td>0.904681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901308</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925568</td>\n",
       "      <td>0.919698</td>\n",
       "      <td>9.258439e-01</td>\n",
       "      <td>9.213455e-01</td>\n",
       "      <td>0.921746</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.002440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.114375</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>14</td>\n",
       "      <td>{'hidden_layer_sizes': 14}</td>\n",
       "      <td>0.881882</td>\n",
       "      <td>0.914432</td>\n",
       "      <td>8.931469e-01</td>\n",
       "      <td>0.910673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>0.012831</td>\n",
       "      <td>4</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.919693</td>\n",
       "      <td>9.253539e-01</td>\n",
       "      <td>9.215457e-01</td>\n",
       "      <td>0.927189</td>\n",
       "      <td>0.923854</td>\n",
       "      <td>0.002782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.234449</td>\n",
       "      <td>0.072384</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>15</td>\n",
       "      <td>{'hidden_layer_sizes': 15}</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.915696</td>\n",
       "      <td>8.895166e-01</td>\n",
       "      <td>0.895793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895098</td>\n",
       "      <td>0.014773</td>\n",
       "      <td>6</td>\n",
       "      <td>0.935362</td>\n",
       "      <td>0.925134</td>\n",
       "      <td>9.300960e-01</td>\n",
       "      <td>9.268663e-01</td>\n",
       "      <td>0.932838</td>\n",
       "      <td>0.930059</td>\n",
       "      <td>0.003750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.287214</td>\n",
       "      <td>0.045523</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>16</td>\n",
       "      <td>{'hidden_layer_sizes': 16}</td>\n",
       "      <td>0.844236</td>\n",
       "      <td>0.912114</td>\n",
       "      <td>8.740659e-01</td>\n",
       "      <td>0.883119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877191</td>\n",
       "      <td>0.021787</td>\n",
       "      <td>16</td>\n",
       "      <td>0.944283</td>\n",
       "      <td>0.928321</td>\n",
       "      <td>9.423364e-01</td>\n",
       "      <td>9.368196e-01</td>\n",
       "      <td>0.939547</td>\n",
       "      <td>0.938261</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.038157</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>17</td>\n",
       "      <td>{'hidden_layer_sizes': 17}</td>\n",
       "      <td>0.865420</td>\n",
       "      <td>0.897112</td>\n",
       "      <td>8.867127e-01</td>\n",
       "      <td>0.874969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880162</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>15</td>\n",
       "      <td>0.896163</td>\n",
       "      <td>0.888663</td>\n",
       "      <td>8.938006e-01</td>\n",
       "      <td>8.953021e-01</td>\n",
       "      <td>0.894799</td>\n",
       "      <td>0.893746</td>\n",
       "      <td>0.002654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.252750</td>\n",
       "      <td>0.040013</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>18</td>\n",
       "      <td>{'hidden_layer_sizes': 18}</td>\n",
       "      <td>0.879907</td>\n",
       "      <td>0.916453</td>\n",
       "      <td>8.738326e-01</td>\n",
       "      <td>0.898478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890866</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>10</td>\n",
       "      <td>0.934163</td>\n",
       "      <td>0.933182</td>\n",
       "      <td>9.353222e-01</td>\n",
       "      <td>9.239234e-01</td>\n",
       "      <td>0.935639</td>\n",
       "      <td>0.932446</td>\n",
       "      <td>0.004350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.287135</td>\n",
       "      <td>0.030004</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>19</td>\n",
       "      <td>{'hidden_layer_sizes': 19}</td>\n",
       "      <td>0.875270</td>\n",
       "      <td>0.918799</td>\n",
       "      <td>8.895017e-01</td>\n",
       "      <td>0.891289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891343</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>9</td>\n",
       "      <td>0.930415</td>\n",
       "      <td>0.933071</td>\n",
       "      <td>9.310814e-01</td>\n",
       "      <td>9.281913e-01</td>\n",
       "      <td>0.935127</td>\n",
       "      <td>0.931577</td>\n",
       "      <td>0.002362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.061173      0.050534         0.001699        0.000752   \n",
       "1        0.035286      0.023341         0.001399        0.000385   \n",
       "2        0.042964      0.017307         0.001403        0.000590   \n",
       "3        0.102883      0.025518         0.001504        0.000324   \n",
       "4        0.031189      0.016439         0.000896        0.000199   \n",
       "5        0.081259      0.043442         0.001409        0.000599   \n",
       "6        0.187866      0.046103         0.001099        0.000207   \n",
       "7        0.137570      0.055958         0.001100        0.000208   \n",
       "8        0.039279      0.007689         0.001001        0.000324   \n",
       "9        0.145339      0.029413         0.001197        0.000402   \n",
       "10       0.158379      0.025939         0.000897        0.000201   \n",
       "11       0.263664      0.058515         0.000903        0.000204   \n",
       "12       0.115281      0.043370         0.001194        0.000674   \n",
       "13       0.114375      0.036105         0.000894        0.000199   \n",
       "14       0.234449      0.072384         0.001002        0.000018   \n",
       "15       0.287214      0.045523         0.000803        0.000250   \n",
       "16       0.038157      0.008598         0.000898        0.000201   \n",
       "17       0.252750      0.040013         0.000796        0.000398   \n",
       "18       0.287135      0.030004         0.000794        0.000244   \n",
       "\n",
       "   param_hidden_layer_sizes                      params  split0_test_score  \\\n",
       "0                         1   {'hidden_layer_sizes': 1}           0.804930   \n",
       "1                         2   {'hidden_layer_sizes': 2}           0.871815   \n",
       "2                         3   {'hidden_layer_sizes': 3}           0.865441   \n",
       "3                         4   {'hidden_layer_sizes': 4}           0.884422   \n",
       "4                         5   {'hidden_layer_sizes': 5}           0.875237   \n",
       "5                         6   {'hidden_layer_sizes': 6}           0.865394   \n",
       "6                         7   {'hidden_layer_sizes': 7}           0.881704   \n",
       "7                         8   {'hidden_layer_sizes': 8}           0.868913   \n",
       "8                         9   {'hidden_layer_sizes': 9}           0.865427   \n",
       "9                        10  {'hidden_layer_sizes': 10}           0.872870   \n",
       "10                       11  {'hidden_layer_sizes': 11}           0.877578   \n",
       "11                       12  {'hidden_layer_sizes': 12}           0.857073   \n",
       "12                       13  {'hidden_layer_sizes': 13}           0.884102   \n",
       "13                       14  {'hidden_layer_sizes': 14}           0.881882   \n",
       "14                       15  {'hidden_layer_sizes': 15}           0.871245   \n",
       "15                       16  {'hidden_layer_sizes': 16}           0.844236   \n",
       "16                       17  {'hidden_layer_sizes': 17}           0.865420   \n",
       "17                       18  {'hidden_layer_sizes': 18}           0.879907   \n",
       "18                       19  {'hidden_layer_sizes': 19}           0.875270   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0            0.897256       6.281043e-01           0.834395  ...   \n",
       "1            0.908073      -9.021308e-07          -0.002838  ...   \n",
       "2            0.897130       8.867137e-01           0.874968  ...   \n",
       "3            0.914900       8.889936e-01           0.906389  ...   \n",
       "4           -0.029371      -9.024328e-07           0.882977  ...   \n",
       "5            0.897123       8.922768e-01           0.874962  ...   \n",
       "6            0.916310       8.848166e-01           0.904719  ...   \n",
       "7            0.914378       8.902135e-01           0.902263  ...   \n",
       "8            0.897119       8.867123e-01           0.874973  ...   \n",
       "9            0.912837       8.885163e-01           0.905346  ...   \n",
       "10           0.914986       8.934466e-01           0.891841  ...   \n",
       "11           0.910600       8.806527e-01           0.905348  ...   \n",
       "12           0.914332       8.934573e-01           0.904681  ...   \n",
       "13           0.914432       8.931469e-01           0.910673  ...   \n",
       "14           0.915696       8.895166e-01           0.895793  ...   \n",
       "15           0.912114       8.740659e-01           0.883119  ...   \n",
       "16           0.897112       8.867127e-01           0.874969  ...   \n",
       "17           0.916453       8.738326e-01           0.898478  ...   \n",
       "18           0.918799       8.895017e-01           0.891289  ...   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0          0.776330        0.094136               17            0.813319   \n",
       "1          0.532584        0.436167               18            0.904814   \n",
       "2          0.880169        0.010837               13            0.896163   \n",
       "3          0.899402        0.011226                2            0.928724   \n",
       "4          0.522945        0.439086               19            0.904786   \n",
       "5          0.888019        0.016010               12            0.896163   \n",
       "6          0.895306        0.013151                5            0.925483   \n",
       "7          0.894286        0.015030                7            0.930957   \n",
       "8          0.880168        0.010836               14            0.896163   \n",
       "9          0.897932        0.015111                3            0.930840   \n",
       "10         0.892323        0.012695                8            0.930269   \n",
       "11         0.888682        0.019094               11            0.937404   \n",
       "12         0.901308        0.011079                1            0.925568   \n",
       "13         0.897527        0.012831                4            0.925490   \n",
       "14         0.895098        0.014773                6            0.935362   \n",
       "15         0.877191        0.021787               16            0.944283   \n",
       "16         0.880162        0.010837               15            0.896163   \n",
       "17         0.890866        0.015166               10            0.934163   \n",
       "18         0.891343        0.014870                9            0.930415   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0             0.888642        6.828197e-01        8.636990e-01   \n",
       "1             0.896733       -4.440892e-15       -4.218847e-15   \n",
       "2             0.888663        8.938006e-01        8.953021e-01   \n",
       "3             0.919772        9.295066e-01        9.256012e-01   \n",
       "4             0.000000       -5.995204e-15        9.048456e-01   \n",
       "5             0.888663        9.260035e-01        8.953021e-01   \n",
       "6             0.930465        9.340075e-01        9.252127e-01   \n",
       "7             0.924777        9.302323e-01        9.244407e-01   \n",
       "8             0.888663        8.938006e-01        8.953021e-01   \n",
       "9             0.922817        9.287350e-01        9.236658e-01   \n",
       "10            0.919113        9.258400e-01        9.230312e-01   \n",
       "11            0.927438        9.340613e-01        9.310227e-01   \n",
       "12            0.919698        9.258439e-01        9.213455e-01   \n",
       "13            0.919693        9.253539e-01        9.215457e-01   \n",
       "14            0.925134        9.300960e-01        9.268663e-01   \n",
       "15            0.928321        9.423364e-01        9.368196e-01   \n",
       "16            0.888663        8.938006e-01        8.953021e-01   \n",
       "17            0.933182        9.353222e-01        9.239234e-01   \n",
       "18            0.933071        9.310814e-01        9.281913e-01   \n",
       "\n",
       "    split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.782727          0.806241         0.072010  \n",
       "1             0.903874          0.541084         0.441802  \n",
       "2             0.894799          0.893746         0.002654  \n",
       "3             0.925822          0.925885         0.003424  \n",
       "4             0.903875          0.542701         0.443114  \n",
       "5             0.921885          0.905603         0.015254  \n",
       "6             0.932478          0.929529         0.003595  \n",
       "7             0.926575          0.927396         0.002720  \n",
       "8             0.894799          0.893746         0.002654  \n",
       "9             0.921748          0.925561         0.003567  \n",
       "10            0.929766          0.925604         0.004193  \n",
       "11            0.928853          0.931756         0.003601  \n",
       "12            0.921746          0.922840         0.002440  \n",
       "13            0.927189          0.923854         0.002782  \n",
       "14            0.932838          0.930059         0.003750  \n",
       "15            0.939547          0.938261         0.005575  \n",
       "16            0.894799          0.893746         0.002654  \n",
       "17            0.935639          0.932446         0.004350  \n",
       "18            0.935127          0.931577         0.002362  \n",
       "\n",
       "[19 rows x 21 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [i for i in range(1,20)] \n",
    "}\n",
    "gridSearch = GridSearchCV(MLPRegressor(activation='relu', solver='lbfgs', random_state=1, max_iter=1000), \n",
    "                          param_grid, cv=5, n_jobs=-1, return_train_score=True)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print('Best score: ', gridSearch.best_score_)\n",
    "print('Best parameters: ', gridSearch.best_params_)\n",
    "pd.DataFrame(data=gridSearch.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ch-11-ProbSolutions-NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
